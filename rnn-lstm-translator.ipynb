{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab2f4e72",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1767199313154,
     "user": {
      "displayName": "Apb Reloaded",
      "userId": "14539421398603321875"
     },
     "user_tz": -120
    },
    "id": "ab2f4e72"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "from pickle import dump, load\n",
    "from unicodedata import normalize\n",
    "from numpy import array, argmax\n",
    "from numpy.random import rand, shuffle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical, plot_model, pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import LSTM, Dense, Embedding, RepeatVector, TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dab970",
   "metadata": {
    "id": "47dab970"
   },
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8bee8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11753,
     "status": "ok",
     "timestamp": 1767199324911,
     "user": {
      "displayName": "Apb Reloaded",
      "userId": "14539421398603321875"
     },
     "user_tz": -120
    },
    "id": "1f8bee8b",
    "outputId": "3621520a-914d-4411-b777-cafae424219e"
   },
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in lines]\n",
    "    return pairs\n",
    "\n",
    "def clean_pairs(lines):\n",
    "\tcleaned = list()\n",
    "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "\ttable = str.maketrans('', '', string.punctuation)\n",
    "\tfor pair in lines:\n",
    "\t\tclean_pair = list()\n",
    "\t\tfor line in pair:\n",
    "\t\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "\t\t\tline = line.decode('UTF-8')\n",
    "\t\t\tline = line.split()\n",
    "\t\t\tline = [word.lower() for word in line]\n",
    "\t\t\tline = [word.translate(table) for word in line]\n",
    "\t\t\tline = [re_print.sub('', w) for w in line]\n",
    "\t\t\tline = [word for word in line if word.isalpha()]\n",
    "\t\t\tclean_pair.append(' '.join(line))\n",
    "\t\tcleaned.append(clean_pair)\n",
    "\treturn array(cleaned)\n",
    "\n",
    "def save_clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    "\n",
    "def load_clean_data(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "\n",
    "file1 = './content/data/fra_eng.pkl'\n",
    "file2 = './content/data/fra_eng_both.pkl'\n",
    "file3 = './content/data/fra_eng_train.pkl'\n",
    "file4 = './content/data/fra_eng_test.pkl'\n",
    "\n",
    "# Checking if all preprocessed files exist\n",
    "if os.path.exists(file1) and os.path.exists(file2) and os.path.exists(file3) and os.path.exists(file4):\n",
    "    print(\"Preprocessed files already exist. Skipping data preparation.\")\n",
    "else:\n",
    "\tfilename = './content/data/fra.txt'\n",
    "\tdoc = load_doc(filename)\n",
    "\tpairs = to_pairs(doc)\n",
    "\tcleaned_pairs = clean_pairs(pairs)\n",
    "\tsave_clean_data(cleaned_pairs, './content/data/fra_eng.pkl')\n",
    "\n",
    "\tfor i in range(100):\n",
    "\t\tprint('[%s] => [%s]' % (cleaned_pairs[i,0], cleaned_pairs[i,1]))\n",
    "\n",
    "\traw_dataset = load_clean_data('./content/data/fra_eng.pkl')\n",
    "\tn_sentences = 15000\n",
    "\tdataset = raw_dataset[:n_sentences, :]\n",
    "\tshuffle(dataset)\n",
    "\ttrain, test =  dataset[:12000], dataset[12000:]\n",
    "\n",
    "\tsave_clean_data(dataset, './content/data/fra_eng_both.pkl')\n",
    "\tsave_clean_data(train, './content/data/fra_eng_train.pkl')\n",
    "\tsave_clean_data(test, './content/data/fra_eng_test.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d11a3",
   "metadata": {
    "id": "d55d11a3"
   },
   "source": [
    "Sequence Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ec5b54",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1767199324923,
     "user": {
      "displayName": "Apb Reloaded",
      "userId": "14539421398603321875"
     },
     "user_tz": -120
    },
    "id": "41ec5b54"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)\n",
    "\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X\n",
    "\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e720ac6",
   "metadata": {
    "id": "6e720ac6"
   },
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e595e993",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1767199324933,
     "user": {
      "displayName": "Apb Reloaded",
      "userId": "14539421398603321875"
     },
     "user_tz": -120
    },
    "id": "e595e993"
   },
   "outputs": [],
   "source": [
    "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add((LSTM(n_units)))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add((LSTM(n_units, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7c5ed",
   "metadata": {
    "id": "73b7c5ed"
   },
   "source": [
    "English/French Tokenizers & Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9508b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1767199325299,
     "user": {
      "displayName": "Apb Reloaded",
      "userId": "14539421398603321875"
     },
     "user_tz": -120
    },
    "id": "bc9508b5",
    "outputId": "5c3aae0a-defa-4f84-d320-033d4551866d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 2888\n",
      "English Max Length: 5\n",
      "\n",
      "French Vocabulary Size: 5797\n",
      "French Max Length: 11\n"
     ]
    }
   ],
   "source": [
    "dataset = load_clean_data('./content/data/fra_eng_both.pkl')\n",
    "train = load_clean_data('./content/data/fra_eng_train.pkl')\n",
    "test = load_clean_data('./content/data/fra_eng_test.pkl')\n",
    "\n",
    "eng_tokenizer = create_tokenizer(dataset[:,0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:,0])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length) + \"\\n\")\n",
    "\n",
    "fra_tokenizer = create_tokenizer(dataset[:,1])\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "fra_length = max_length(dataset[:,1])\n",
    "print('French Vocabulary Size: %d' % fra_vocab_size)\n",
    "print('French Max Length: %d' % (fra_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd9f557",
   "metadata": {
    "id": "6bd9f557"
   },
   "source": [
    "Preparing Training/Testing Data & Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "096b8482",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 2003,
     "status": "ok",
     "timestamp": 1767199327334,
     "user": {
      "displayName": "Apb Reloaded",
      "userId": "14539421398603321875"
     },
     "user_tz": -120
    },
    "id": "096b8482",
    "outputId": "fda3bb8d-9672-490e-b3d1-6fd7bb60798c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 11, 256)           1484032   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               525312    \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 5, 256)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 5, 256)            525312    \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 5, 2888)          742216    \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,276,872\n",
      "Trainable params: 3,276,872\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainX = encode_sequences(fra_tokenizer, fra_length, train[:,1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:,0])\n",
    "trainY = encode_output(trainY, eng_vocab_size)\n",
    "\n",
    "testX = encode_sequences(fra_tokenizer, fra_length, test[:,1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:,0])\n",
    "testY = encode_output(testY, eng_vocab_size)\n",
    "\n",
    "model = define_model(fra_vocab_size, eng_vocab_size, fra_length, eng_length, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, fra_length))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#plot_model(model, to_file='./content/model-architecture.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915971f6",
   "metadata": {
    "id": "915971f6"
   },
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bcb6724",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 116535,
     "status": "ok",
     "timestamp": 1767199443872,
     "user": {
      "displayName": "Apb Reloaded",
      "userId": "14539421398603321875"
     },
     "user_tz": -120
    },
    "id": "5bcb6724",
    "outputId": "968cf7a5-bd54-4a9b-d125-acfdc15c132f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 3.66002, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 7s - 39ms/step - accuracy: 0.4209 - loss: 4.2932 - val_accuracy: 0.4389 - val_loss: 3.6600\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 2: val_loss improved from 3.66002 to 3.47939, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 15ms/step - accuracy: 0.4485 - loss: 3.4838 - val_accuracy: 0.4515 - val_loss: 3.4794\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 3: val_loss improved from 3.47939 to 3.32393, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 6s - 30ms/step - accuracy: 0.4631 - loss: 3.2548 - val_accuracy: 0.4645 - val_loss: 3.3239\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 4: val_loss improved from 3.32393 to 3.20305, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 15ms/step - accuracy: 0.4833 - loss: 3.0762 - val_accuracy: 0.4873 - val_loss: 3.2031\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 5: val_loss improved from 3.20305 to 3.07668, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 5s - 28ms/step - accuracy: 0.5087 - loss: 2.8995 - val_accuracy: 0.5059 - val_loss: 3.0767\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 6: val_loss improved from 3.07668 to 2.96162, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 18ms/step - accuracy: 0.5268 - loss: 2.7332 - val_accuracy: 0.5233 - val_loss: 2.9616\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 7: val_loss improved from 2.96162 to 2.84261, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 15ms/step - accuracy: 0.5498 - loss: 2.5670 - val_accuracy: 0.5439 - val_loss: 2.8426\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 8: val_loss improved from 2.84261 to 2.72791, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 15ms/step - accuracy: 0.5717 - loss: 2.4003 - val_accuracy: 0.5588 - val_loss: 2.7279\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 9: val_loss improved from 2.72791 to 2.63881, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 15ms/step - accuracy: 0.5928 - loss: 2.2334 - val_accuracy: 0.5743 - val_loss: 2.6388\n",
      "Epoch 10/30\n",
      "\n",
      "Epoch 10: val_loss improved from 2.63881 to 2.53738, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 5s - 28ms/step - accuracy: 0.6111 - loss: 2.0773 - val_accuracy: 0.5845 - val_loss: 2.5374\n",
      "Epoch 11/30\n",
      "\n",
      "Epoch 11: val_loss improved from 2.53738 to 2.47378, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 5s - 26ms/step - accuracy: 0.6298 - loss: 1.9253 - val_accuracy: 0.5943 - val_loss: 2.4738\n",
      "Epoch 12/30\n",
      "\n",
      "Epoch 12: val_loss improved from 2.47378 to 2.39011, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 16ms/step - accuracy: 0.6449 - loss: 1.7912 - val_accuracy: 0.6079 - val_loss: 2.3901\n",
      "Epoch 13/30\n",
      "\n",
      "Epoch 13: val_loss improved from 2.39011 to 2.34991, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 19ms/step - accuracy: 0.6612 - loss: 1.6637 - val_accuracy: 0.6099 - val_loss: 2.3499\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 14: val_loss improved from 2.34991 to 2.30221, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 17ms/step - accuracy: 0.6787 - loss: 1.5459 - val_accuracy: 0.6179 - val_loss: 2.3022\n",
      "Epoch 15/30\n",
      "\n",
      "Epoch 15: val_loss improved from 2.30221 to 2.25440, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 5s - 26ms/step - accuracy: 0.6944 - loss: 1.4370 - val_accuracy: 0.6289 - val_loss: 2.2544\n",
      "Epoch 16/30\n",
      "\n",
      "Epoch 16: val_loss improved from 2.25440 to 2.22829, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 18ms/step - accuracy: 0.7114 - loss: 1.3315 - val_accuracy: 0.6329 - val_loss: 2.2283\n",
      "Epoch 17/30\n",
      "\n",
      "Epoch 17: val_loss improved from 2.22829 to 2.19852, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 15ms/step - accuracy: 0.7277 - loss: 1.2320 - val_accuracy: 0.6399 - val_loss: 2.1985\n",
      "Epoch 18/30\n",
      "\n",
      "Epoch 18: val_loss improved from 2.19852 to 2.17275, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 5s - 29ms/step - accuracy: 0.7455 - loss: 1.1385 - val_accuracy: 0.6446 - val_loss: 2.1727\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 19: val_loss improved from 2.17275 to 2.14142, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 17ms/step - accuracy: 0.7615 - loss: 1.0500 - val_accuracy: 0.6501 - val_loss: 2.1414\n",
      "Epoch 20/30\n",
      "\n",
      "Epoch 20: val_loss improved from 2.14142 to 2.12049, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 16ms/step - accuracy: 0.7783 - loss: 0.9687 - val_accuracy: 0.6551 - val_loss: 2.1205\n",
      "Epoch 21/30\n",
      "\n",
      "Epoch 21: val_loss improved from 2.12049 to 2.10407, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 15ms/step - accuracy: 0.7939 - loss: 0.8882 - val_accuracy: 0.6601 - val_loss: 2.1041\n",
      "Epoch 22/30\n",
      "\n",
      "Epoch 22: val_loss improved from 2.10407 to 2.08651, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 15ms/step - accuracy: 0.8113 - loss: 0.8144 - val_accuracy: 0.6675 - val_loss: 2.0865\n",
      "Epoch 23/30\n",
      "\n",
      "Epoch 23: val_loss improved from 2.08651 to 2.07564, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 16ms/step - accuracy: 0.8287 - loss: 0.7423 - val_accuracy: 0.6691 - val_loss: 2.0756\n",
      "Epoch 24/30\n",
      "\n",
      "Epoch 24: val_loss improved from 2.07564 to 2.05959, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 5s - 26ms/step - accuracy: 0.8436 - loss: 0.6793 - val_accuracy: 0.6749 - val_loss: 2.0596\n",
      "Epoch 25/30\n",
      "\n",
      "Epoch 25: val_loss improved from 2.05959 to 2.04630, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 5s - 27ms/step - accuracy: 0.8579 - loss: 0.6202 - val_accuracy: 0.6787 - val_loss: 2.0463\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 26: val_loss did not improve from 2.04630\n",
      "188/188 - 3s - 17ms/step - accuracy: 0.8692 - loss: 0.5693 - val_accuracy: 0.6807 - val_loss: 2.0585\n",
      "Epoch 27/30\n",
      "\n",
      "Epoch 27: val_loss did not improve from 2.04630\n",
      "188/188 - 3s - 15ms/step - accuracy: 0.8820 - loss: 0.5180 - val_accuracy: 0.6830 - val_loss: 2.0498\n",
      "Epoch 28/30\n",
      "\n",
      "Epoch 28: val_loss improved from 2.04630 to 2.03769, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 3s - 15ms/step - accuracy: 0.8908 - loss: 0.4755 - val_accuracy: 0.6859 - val_loss: 2.0377\n",
      "Epoch 29/30\n",
      "\n",
      "Epoch 29: val_loss improved from 2.03769 to 2.03437, saving model to ./content/eng-fra-model.keras\n",
      "188/188 - 6s - 30ms/step - accuracy: 0.9006 - loss: 0.4346 - val_accuracy: 0.6891 - val_loss: 2.0344\n",
      "Epoch 30/30\n",
      "\n",
      "Epoch 30: val_loss did not improve from 2.03437\n",
      "188/188 - 3s - 15ms/step - accuracy: 0.9080 - loss: 0.3968 - val_accuracy: 0.6880 - val_loss: 2.0423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e74f58dabd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = './content/eng-fra-model.keras'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f27ad1f",
   "metadata": {
    "id": "1f27ad1f"
   },
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99e59049",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1654,
     "status": "ok",
     "timestamp": 1767199445536,
     "user": {
      "displayName": "Apb Reloaded",
      "userId": "14539421398603321875"
     },
     "user_tz": -120
    },
    "id": "99e59049",
    "outputId": "4c37550f-d57e-4087-f259-4f0de56abd6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Evaluation\n",
      "src=[jai besoin detudier], target=[i need to study], predicted=[i need to study]\n",
      "src=[tom est un heros], target=[tom is a hero], predicted=[tom is a hero]\n",
      "src=[quel gros chien], target=[what a big dog], predicted=[what a big dog]\n",
      "src=[ce sont les maths que je prefere], target=[i like math best], predicted=[i like your you]\n",
      "src=[je te crois vraiment], target=[i do believe you], predicted=[i do believe you]\n",
      "src=[je men chargerai], target=[ill handle this], predicted=[ill handle it]\n",
      "src=[je les ai soudoyees], target=[i bribed them], predicted=[i bribed them]\n",
      "src=[puisje aller au lit], target=[may i go to bed], predicted=[may i go to bed]\n",
      "src=[je ne laime pas], target=[i dont like him], predicted=[i dont like it]\n",
      "src=[jai un ranch], target=[i have a ranch], predicted=[i have a ranch]\n",
      "BLEU-1: 0.897436\n",
      "BLEU-2: 0.879575\n",
      "BLEU-3: 0.862512\n",
      "BLEU-4: 0.789582\n",
      "\n",
      "Testing Data Evaluation\n",
      "src=[jarrive a le ressentir], target=[i can feel it], predicted=[i can remember it]\n",
      "src=[jaime pecher], target=[i like fishing], predicted=[i like hiking]\n",
      "src=[battez les ufs], target=[beat the eggs], predicted=[beat some eggs]\n",
      "src=[estu prete], target=[are you ready], predicted=[are you ready]\n",
      "src=[je veux men aller], target=[i want to go], predicted=[i want to go]\n",
      "src=[je me suis amuse], target=[i did have fun], predicted=[i had some]\n",
      "src=[je craque], target=[im cracking up], predicted=[i check first]\n",
      "src=[jai echoue], target=[ive failed], predicted=[i failed]\n",
      "src=[tom begaie], target=[tom stutters], predicted=[tom is]\n",
      "src=[ils mont souhaite la bienvenue], target=[they greeted me], predicted=[they greeted me]\n",
      "BLEU-1: 0.644811\n",
      "BLEU-2: 0.529766\n",
      "BLEU-3: 0.484756\n",
      "BLEU-4: 0.305861\n"
     ]
    }
   ],
   "source": [
    "def word_for_id(integer, tokenizer):\n",
    "\tfor word, index in tokenizer.word_index.items():\n",
    "\t\tif index == integer:\n",
    "\t\t\treturn word\n",
    "\treturn None\n",
    "\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "\tprediction = model.predict(source, verbose=0)[0]\n",
    "\tintegers = [argmax(vector) for vector in prediction]\n",
    "\ttarget = list()\n",
    "\tfor i in integers:\n",
    "\t\tword = word_for_id(i, tokenizer)\n",
    "\t\tif word is None:\n",
    "\t\t\tbreak\n",
    "\t\ttarget.append(word)\n",
    "\treturn ' '.join(target)\n",
    "\n",
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "\tactual, predicted = list(), list()\n",
    "\tfor i, source in enumerate(sources):\n",
    "\t\t# translate encoded source text\n",
    "\t\tsource = source.reshape((1, source.shape[0]))\n",
    "\t\ttranslation = predict_sequence(model, eng_tokenizer, source)\n",
    "\t\traw_target, raw_src = raw_dataset[i]\n",
    "\t\tif i < 10:\n",
    "\t\t\tprint('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
    "\t\tactual.append([raw_target.split()])\n",
    "\t\tpredicted.append(translation.split())\n",
    "\t# calculate BLEU score\n",
    "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "\n",
    "model = load_model('./content/eng-fra-model.keras')\n",
    "\n",
    "print('Training Data Evaluation')\n",
    "evaluate_model(model, eng_tokenizer, trainX[:10], train[:10])\n",
    "\n",
    "print(\"\\n\" 'Testing Data Evaluation')\n",
    "evaluate_model(model, eng_tokenizer, testX[:10], test[:10])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfdml_plugin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
